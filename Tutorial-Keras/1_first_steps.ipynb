{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Below is an overview of the 5 steps in the neural network model life-cycle in Keras that we are going to look at.\n",
    "\n",
    "1) Define Network.\n",
    "\n",
    "2) Compile Network.\n",
    "\n",
    "3) Fit Network.\n",
    "\n",
    "4) Evaluate Network.\n",
    "\n",
    "5) Make Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Tutorial from https://machinelearningmastery.com/5-step-life-cycle-neural-network-models-keras/\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Concatenate, Input, Activation\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Network\n",
    "\n",
    "The first step is to define your neural network.\n",
    "\n",
    "Neural networks are defined in Keras as a sequence of layers. The container for these layers is the Sequential class.\n",
    "\n",
    "The first step is to create an instance of the Sequential class. Then you can create your layers and add them in the order that they should be connected.\n",
    "\n",
    "Think of a Sequential model as a pipeline with your raw data fed in at the bottom and predictions that come out at the top.\n",
    "\n",
    "This is a helpful conception in Keras as concerns that were traditionally associated with a layer can also be split out and added as separate layers, clearly showing their role in the transform of data from input to prediction. For example, activation functions that transform a summed signal from each neuron in a layer can be extracted and added to the Sequential as a layer-like object called Activation.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "```\n",
    "\n",
    "The choice of activation function is most important for the output layer as it will define the format that predictions will take.\n",
    "\n",
    "For example, below are some common predictive modeling problem types and the structure and standard activation function that you can use in the output layer:\n",
    "\n",
    "$\\bullet$ **Regression:** Linear activation function or ‘linear’ and the number of neurons matching the number of outputs.\n",
    "\n",
    "$\\bullet$ **Binary Classification (2 class):** Logistic activation function or ‘sigmoid’ and one neuron the output layer.\n",
    "\n",
    "$\\bullet$ **Multiclass Classification (>2 class):** Softmax activation function or ‘softmax’ and one output neuron per class value, assuming a one-hot encoded output pattern.\n",
    "\n",
    "## 2. Compile Network\n",
    "\n",
    "Once we have defined our network, we must compile it.\n",
    "\n",
    "Compilation is an efficiency step. It transforms the simple sequence of layers that we defined into a highly efficient series of matrix transforms in a format intended to be executed on your GPU or CPU, depending on how Keras is configured.\n",
    "\n",
    "Think of compilation as a precompute step for your network.\n",
    "\n",
    "Compilation is always required after defining a model. This includes both before training it using an optimization scheme as well as loading a set of pre-trained weights from a save file. The reason is that the compilation step prepares an efficient representation of the network that is also required to make predictions on your hardware.\n",
    "\n",
    "Compilation requires a number of parameters to be specified, specifically tailored to training your network. Specifically the optimization algorithm to use to train the network and the loss function used to evaluate the network that is minimized by the optimization algorithm.\n",
    "\n",
    "For example, below is a case of compiling a defined model and specifying the stochastic gradient descent (sgd) optimization algorithm and the mean squared error (mse) loss function, intended for a regression type problem.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "```\n",
    "\n",
    "The type of predictive modeling problem imposes constraints on the type of loss function that can be used. Below are some standard loss functions for different predictive model types:\n",
    "\n",
    "$\\bullet$ **Regression:** Mean Squared Error or ‘mse‘.\n",
    "\n",
    "$\\bullet$ **Binary Classification (2 class):** Logarithmic Loss, also called cross entropy or ‘binary_crossentropy‘.\n",
    "\n",
    "$\\bullet$ **Multiclass Classification (>2 class):** Multiclass Logarithmic Loss or ‘categorical_crossentropy‘.\n",
    "You can review the suite of loss functions supported by Keras.\n",
    "\n",
    "The most common optimization algorithm is stochastic gradient descent, but Keras also supports a suite of other state of the art optimization algorithms.\n",
    "\n",
    "Perhaps the most commonly used optimization algorithms because of their generally better performance are:\n",
    "\n",
    "$\\bullet$ **Stochastic Gradient Descent** or ‘sgd‘ that requires the tuning of a learning rate and momentum.\n",
    "\n",
    "$\\bullet$ **ADAM** or ‘adam‘ that requires the tuning of learning rate.\n",
    "\n",
    "$\\bullet$ **RMSprop** or ‘rmsprop‘ that requires the tuning of learning rate.\n",
    "\n",
    "Finally, you can also specify metrics to collect while fitting your model in addition to the loss function. Generally, the most useful additional metric to collect is accuracy for classification problems. The metrics to collect are specified by name in an array.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "## 3. Fit Network\n",
    "\n",
    "Once the network is compiled, it can be fit, which means adapt the weights on a training dataset.\n",
    "\n",
    "Fitting the network requires the training data to be specified, both a matrix of input patterns X and an array of matching output patterns y.\n",
    "\n",
    "The network is trained using the backpropagation algorithm and optimized according to the optimization algorithm and loss function specified when compiling the model.\n",
    "\n",
    "The backpropagation algorithm requires that the network be trained for a specified number of epochs or exposures to the training dataset.\n",
    "\n",
    "Each epoch can be partitioned into groups of input-output pattern pairs called batches. This define the number of patterns that the network is exposed to before the weights are updated within an epoch. It is also an efficiency optimization, ensuring that not too many input patterns are loaded into memory at a time.\n",
    "\n",
    "A minimal example of fitting a network is as follows:\n",
    "\n",
    "```python\n",
    "history = model.fit(X, y, batch_size=10, epochs=100)\n",
    "```\n",
    "\n",
    "Once fit, a history object is returned that provides a summary of the performance of the model during training. This includes both the loss and any additional metrics specified when compiling the model, recorded each epoch.\n",
    "\n",
    "**Note:** If you are not satisfied with the results after fitting the model, you can run the **fit** function again and it will continue training from where it stopped. More precisely, the weights of your neural network are saved and the **fit** function will use these weights to start training. If you want to reset the weights and start training from scratch, just compile the model again (use the **compile** function described at the previous session).\n",
    "\n",
    "One can run into problems if want to change some parameter (of the optimizer), or some metric, and compile again, because the compilation will reset the weights. To make some changes and start training from the weights from the previous training, it is necessary to save these weights before. To do that, use the command **W = model.get_weights()**. This saves a list of numpy arrays to a list **W.** Before compiling the model, use the command **model.set_weights(W)** to make the model use the weights in **W** as initial weights. Then you can change parameters, compile and start the training from these saved weights.\n",
    "\n",
    "## 4. Evaluate Network\n",
    "\n",
    "Once the network is trained, it can be evaluated.\n",
    "\n",
    "The network can be evaluated on the training data, but this will not provide a useful indication of the performance of the network as a predictive model, as it has seen all of this data before.\n",
    "\n",
    "We can evaluate the performance of the network on a separate dataset, unseen during testing. This will provide an estimate of the performance of the network at making predictions for unseen data in the future.\n",
    "\n",
    "The model evaluates the loss across all of the test patterns, as well as any other metrics specified when the model was compiled, like classification accuracy. A list of evaluation metrics is returned.\n",
    "\n",
    "For example, for a model compiled with the accuracy metric, we could evaluate it on a new dataset as follows:\n",
    "\n",
    "```python\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "```\n",
    "\n",
    "## 5. Make Predictions\n",
    "\n",
    "Finally, once we are satisfied with the performance of our fit model, we can use it to make predictions on new data.\n",
    "\n",
    "This is as easy as calling the **predict()** function on the model with an array of new input patterns.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "predictions = model.predict(x)\n",
    "```\n",
    "\n",
    "The predictions will be returned in the format provided by the output layer of the network.\n",
    "\n",
    "In the case of a regression problem, these predictions may be in the format of the problem directly, provided by a linear activation function.\n",
    "\n",
    "For a binary classification problem, the predictions may be an array of probabilities for the first class that can be converted to a $1$ or $0$ by rounding.\n",
    "\n",
    "For a multiclass classification problem, the results may be in the form of an array of probabilities (assuming a one hot encoded output variable) that may need to be converted to a single class output prediction using the argmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. End-to-End Worked Example\n",
    "\n",
    "Let’s tie all of this together with a small worked example.\n",
    "\n",
    "This example will use the Pima Indians onset of diabetes binary classification problem, that you can download from the UCI Machine Learning Repository.\n",
    "\n",
    "The problem has $8$ input variables and a single output class variable with the integer values $0$ and $1$.\n",
    "\n",
    "We will construct a Multilayer Perceptron neural network with a $8$ inputs in the visible layer, $12$ neurons in the hidden layer with a rectifier activation function and $1$ neuron in the output layer with a sigmoid activation function.\n",
    "\n",
    "We will train the network for $100$ epochs with a batch size of $10$, optimized using the ADAM optimization algorithm and the logarithmic loss function.\n",
    "\n",
    "Once fit, we will evaluate the model on the training data and then make standalone predictions for the training data. This is for brevity, normally we would evaluate the model on a separate test dataset and make predictions for new data.\n",
    "\n",
    "The complete code listing is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 5.1494 - acc: 0.5742\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 117us/step - loss: 4.7315 - acc: 0.5690\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 132us/step - loss: 4.1861 - acc: 0.5690\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 169us/step - loss: 3.7189 - acc: 0.5547\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 134us/step - loss: 3.4916 - acc: 0.5833\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 195us/step - loss: 1.9295 - acc: 0.5885\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 1.6248 - acc: 0.5638\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 185us/step - loss: 1.2950 - acc: 0.6211\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 204us/step - loss: 1.1402 - acc: 0.6302\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 207us/step - loss: 1.0515 - acc: 0.6432\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 150us/step - loss: 0.9722 - acc: 0.6393\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.9357 - acc: 0.6458\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 226us/step - loss: 0.8924 - acc: 0.6354\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.8723 - acc: 0.6497\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 246us/step - loss: 0.8415 - acc: 0.6497\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.8309 - acc: 0.6432\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.7973 - acc: 0.6432\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.7785 - acc: 0.6484\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.7832 - acc: 0.6536\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 212us/step - loss: 0.7729 - acc: 0.6523\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.7459 - acc: 0.6680\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.7311 - acc: 0.6484\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 239us/step - loss: 0.7216 - acc: 0.6615\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.7512 - acc: 0.6380\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.7411 - acc: 0.6354\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.7502 - acc: 0.6237\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.7163 - acc: 0.6549\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.6946 - acc: 0.6576\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.7161 - acc: 0.6367\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.6966 - acc: 0.6536\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6844 - acc: 0.6628\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.6866 - acc: 0.6497\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6726 - acc: 0.6589\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 275us/step - loss: 0.6616 - acc: 0.6523\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.6551 - acc: 0.6654\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 337us/step - loss: 0.6707 - acc: 0.6784\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.6537 - acc: 0.6732\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.6572 - acc: 0.6667\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 332us/step - loss: 0.6602 - acc: 0.6563\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.6362 - acc: 0.6576\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6304 - acc: 0.6628\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.6321 - acc: 0.6836\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.6435 - acc: 0.6602\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.6439 - acc: 0.6615\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.6178 - acc: 0.6901\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.6586 - acc: 0.6576\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.6234 - acc: 0.6680\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 216us/step - loss: 0.6196 - acc: 0.6836\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.6243 - acc: 0.6745\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.6307 - acc: 0.6823\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.6217 - acc: 0.6797\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 199us/step - loss: 0.6094 - acc: 0.6914\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 218us/step - loss: 0.6203 - acc: 0.6758\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.6051 - acc: 0.6758\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.6142 - acc: 0.6849\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.6218 - acc: 0.6927\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.5994 - acc: 0.6927\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.5941 - acc: 0.6849\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.6045 - acc: 0.6719\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.6049 - acc: 0.6849\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.5847 - acc: 0.7031\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.6038 - acc: 0.6810\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.6042 - acc: 0.6862\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.6121 - acc: 0.6615\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5856 - acc: 0.6914\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.6185 - acc: 0.6706\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 328us/step - loss: 0.5971 - acc: 0.6745\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 254us/step - loss: 0.5954 - acc: 0.6927\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 237us/step - loss: 0.5915 - acc: 0.6966\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5872 - acc: 0.6875\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 369us/step - loss: 0.5810 - acc: 0.6836\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5704 - acc: 0.7083\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5802 - acc: 0.6992\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.5770 - acc: 0.6940\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 144us/step - loss: 0.5640 - acc: 0.7148\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 146us/step - loss: 0.5702 - acc: 0.7031\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 143us/step - loss: 0.5655 - acc: 0.7057\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5802 - acc: 0.6875\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.6170 - acc: 0.6875\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 146us/step - loss: 0.5845 - acc: 0.6914\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5730 - acc: 0.6862\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5814 - acc: 0.6901\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.5519 - acc: 0.7122\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.5625 - acc: 0.7096\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5558 - acc: 0.7070\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 191us/step - loss: 0.5550 - acc: 0.7279\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 155us/step - loss: 0.5604 - acc: 0.7188\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 198us/step - loss: 0.5611 - acc: 0.7135\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 157us/step - loss: 0.5557 - acc: 0.6992\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5590 - acc: 0.7096\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5814 - acc: 0.6979\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 164us/step - loss: 0.5513 - acc: 0.7174\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 182us/step - loss: 0.5481 - acc: 0.7240\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.5469 - acc: 0.7331\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 177us/step - loss: 0.5460 - acc: 0.7292\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5429 - acc: 0.7070\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 189us/step - loss: 0.5532 - acc: 0.7201\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.5492 - acc: 0.7331\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 157us/step - loss: 0.5439 - acc: 0.7201\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 198us/step - loss: 0.5400 - acc: 0.7188\n",
      "768/768 [==============================] - 0s 85us/step\n",
      "\n",
      "Loss: 0.53, Accuracy: 73.31%\n",
      "Prediction Accuracy: 73.31%\n"
     ]
    }
   ],
   "source": [
    "# Sample Multilayer Perceptron Neural Network in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# load and prepare the dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 2. compile the network\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 3. fit the network\n",
    "history = model.fit(X, Y, epochs=100, batch_size=10)\n",
    "# 4. evaluate the network\n",
    "loss, accuracy = model.evaluate(X, Y)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# 5. make predictions\n",
    "probabilities = model.predict(X)\n",
    "predictions = [float(numpy.round(x)) for x in probabilities]\n",
    "accuracy = numpy.mean(predictions == Y)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
